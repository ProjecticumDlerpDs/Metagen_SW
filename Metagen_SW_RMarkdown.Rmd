---
title: "Metagenomic data analysis pipeline"
subtitle: "For Oxford Nanopore Technologiesâ€™ MinION long-read, single-end shotgun sequencing data"
author: "Moreno Serafino"
date: "`r Sys.Date()`"
output:
  html_document: default
  word_document: default
  pdf_document: default
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```


# Introduction

This pipeline is designed for analyzing Next-Generation Sequencing data. The raw data used for testing this pipeline originate from two separate ONT MinION long-read, single-end shotgun DNA-sequencing experiments on ditch water using R9.4.1 flow-cells, presented in fastq format. This Markdown document will therefore use the ditch water experiment data to guide the reader through the analysis pipeline. The point of this pipeline, however, is that data from any other similar sequencing experiment can be used as input. The end result will be a comprehensive overview of microbe composition in origin samples, supported by multiple instances of quality control. 

Note: this markdown document is aimed at people with limited to zero command line experience.

Note: phrases in **bold** specify commands; phrases in *italics* specify scripts.
<br>

### Contents

[inhoudsopgave]
<br>

### Environment setup:

To properly run this pipeline, a number of 'packages' needs to be installed first. These packages are available online and contain the code necessary to execute all downstream scripts and commands. The 'conda' package management system is used to install these packages to a specific 'conda environment', which will help avoid conflicts with other programs present on the server.

**conda update** updates the conda system; it is good practice to update first.<br>
**conda create [name_of_environment]** will create a new environment.<br>
**conda activate [name_of_environment]** will switch the active working directory to that environment and thus activate all installed packages.<br>
**conda install [name_of_package]** will install packages to the currently active conda environment.

For this pipeline, the 'meta' conda environment is created and configured as follows:


```{bash, echo=TRUE, eval=FALSE}

# update conda; 'echo "y"' will automatically answer a confirmation prompt:

echo "y" | conda update -n base conda

# create meta environment:

conda create meta

# activate conda meta environment:

conda activate meta

# install all packages necessary for downstream scripts and commands:

echo "y" | conda install [...]
echo "y" | conda install [...]
echo "y" | conda install [...]

```

Note: The currently active conda environment is always displayed in the terminal between brackets at the start of each line.
<br>

### Library setup:

[blabla]

```{r}

# load libraries:
# ...

```
<br>

### Working directory

The working directory with all the necessary files can be found here: home/1790915/Metagen_SW. Scripts will not work from other directories unless the path is specified. Change your directory with **cd /home/data/1790915/Metagen_SW**. Then check the current working directory with **pwd**. The virtual workspace is now properly set up.
<br>

### About scripts

The next section contains the first bash script. These scripts can simply be run from the terminal. However, most scripts need to know where to find their input data, and where to store their output file(s), among other variables. The scripts are designed so that the user may provide these variables as options. Use **bash [script_name.sh] -h** to print an overview of a script's function and usage. This works for all bash scripts down the line.<br><br><br><br>


# Raw sequencing data overview

The raw data from the ditch water project can be found on the HU server: /home/data/projecticum/SW/raw_data. There are 288 separate .fastq.gz files. For the purposes of testing the pipeline, a subset of 10 files is created. The following files are chosen through random number generation:

fastq_runid_49c9a95cddfedd94200fbd3b545c9c9571fc43c7_17_0.fastq.gz
fastq_runid_49c9a95cddfedd94200fbd3b545c9c9571fc43c7_29_0.fastq.gz
fastq_runid_49c9a95cddfedd94200fbd3b545c9c9571fc43c7_56_0.fastq.gz
fastq_runid_49c9a95cddfedd94200fbd3b545c9c9571fc43c7_78_0.fastq.gz
fastq_runid_49c9a95cddfedd94200fbd3b545c9c9571fc43c7_88_0.fastq.gz
fastq_runid_49c9a95cddfedd94200fbd3b545c9c9571fc43c7_115_0.fastq.gz
fastq_runid_49c9a95cddfedd94200fbd3b545c9c9571fc43c7_173_0.fastq.gz
fastq_runid_49c9a95cddfedd94200fbd3b545c9c9571fc43c7_202_0.fastq.gz
fastq_runid_e0b226454119dd745e929660cd7d0704fc8084f2_16_0.fastq.gz
fastq_runid_e0b226454119dd745e929660cd7d0704fc8084f2_40_0.fastq.gz

These files are copied from the server, and concatenated (combined) into one .fastq.gz file:

```{bash, echo=TRUE, eval=FALSE}

# copy the specified files from the server to the raw_data folder:

cp /home/data/projecticum/SW/raw_data/fastq_runid_49c9a95cddfedd94200fbd3b545c9c9571fc43c7_17_0.fastq.gz ../raw_data
cp /home/data/projecticum/SW/raw_data/fastq_runid_49c9a95cddfedd94200fbd3b545c9c9571fc43c7_29_0.fastq.gz ../raw_data
cp /home/data/projecticum/SW/raw_data/fastq_runid_49c9a95cddfedd94200fbd3b545c9c9571fc43c7_56_0.fastq.gz ../raw_data
cp /home/data/projecticum/SW/raw_data/fastq_runid_49c9a95cddfedd94200fbd3b545c9c9571fc43c7_78_0.fastq.gz ../raw_data
cp /home/data/projecticum/SW/raw_data/fastq_runid_49c9a95cddfedd94200fbd3b545c9c9571fc43c7_88_0.fastq.gz ../raw_data
cp /home/data/projecticum/SW/raw_data/fastq_runid_49c9a95cddfedd94200fbd3b545c9c9571fc43c7_115_0.fastq.gz ../raw_data
cp /home/data/projecticum/SW/raw_data/fastq_runid_49c9a95cddfedd94200fbd3b545c9c9571fc43c7_117_0.fastq.gz ../raw_data
cp /home/data/projecticum/SW/raw_data/fastq_runid_49c9a95cddfedd94200fbd3b545c9c9571fc43c7_202_0.fastq.gz ../raw_data
cp /home/data/projecticum/SW/raw_data/fastq_runid_e0b226454119dd745e929660cd7d0704fc8084f2_16_0.fastq.gz ../raw_data
cp /home/data/projecticum/SW/raw_data/fastq_runid_e0b226454119dd745e929660cd7d0704fc8084f2_40_0.fastq.gz ../raw_data

# concatenate into one file:

zcat /raw_data/fastq_runid* > combined_10.fastq

# compress to limit disk space:
 
gzip /raw_data/combined_10.fastq

# remove the copied (separate) fastq files:

rm /raw_data/fastq_runid*

```

```{bash, echo=TRUE, eval=TRUE}

# check the combined file's format by viewing part of the first read:

zcat raw_data/combined_10.fastq.gz | head -n4 | cut -c1-400

# it should look something like this:

```
<br>

The first line in the read shows the metadata, specifically the type of sequencing experiment the data originates from (in this case R9.4.1 MinION, DNA). 
If your data does not provide clear metadata, a quick summary report can be created through the *FASTQ_summarizer.sh* script. 

```{bash, echo=TRUE, eval=FALSE}

# print the script's function and usage:

bash FASTQ_summarizer.sh -h

# execute the script with proper options:

bash FASTQ_summarizer.sh -I raw_data -O analyse/analyse_misc

```

```{bash, echo=TRUE, eval=TRUE}

# open summary report:

cat analyse/analyse_misc/FASTQ_summary.txt

```

The "longest read length" result provides insight in the type of sequencing data: if this result is 300 basecalls or less, it would be a strong indication that the raw data originates from Illumina short-read sequencing instead of long-read sequencing.<br><br><br><br>

## FastQC report

The FastQC tool will be used to get a quick qualitative overview using the Phred-scores in the dataset. The following script will take the concatenated fastq.gz file, analyze the data and create an html report. The report consists of a number of graphs, the first and most important will be the per base quality score. These boxplots represent the quality values of the entire input per basecall 'location' in the reads, i.e. the quality scores of the first base of each read combined is represented by the first box. Results of this analysis can later be used to trim reads in order to obtain a subset with higher average quality.

```{bash, echo=TRUE, eval=FALSE}
#!/bin/bash

### pseudocode ###

## stap 1: beschrijf de functie en gebruikswijze van het script.
## stap 2: definieer de invoeropties.
## stap 3: voer de FastQC analyse uit d.m.v. fastqc command.


### code ###

## step 1: script description and usage:

print_usage() {
  printf "\nDescription of FastQC_reporter.sh: 
  
  This script can be used to create FastQC reports for fastq.gz files.
  
  Usage: 
  -I input directory with fastq.gz files
  -O output directory (created through script)
  -h for help

  Example cmd line:
	bash FASTQC_reporter.sh 
	-I path/to/FASTQ/data 
	-O new/ouput/directory (can be created through script)\n\n"
}


## step 2: flag definition:

while getopts I:O:h flag; do
  case "${flag}" in
    I) indir="${OPTARG}"  ;;
    O) outdir="${OPTARG}" ;;
    h) print_usage
       exit 1             ;;
    *) echo -e "\nPlease provide valid options (-I and -O are required)."
       echo -e "Use cmd \"bash FASTQC_reporter.sh -h\" for instructions.\n"
       exit 1             ;;
  esac
done


## step 3: FastQC analysis report:

for file in "$indir"/*.fastq.gz
do
    echo "Running FastQC on $file..."
    fastqc "$file" -o "$indir"
done

echo "FastQC analysis complete. Please check $outdir."

```



## FASTQ analysis with NanoPlot

To generate one NanoPlot summary for the entire FASTQ dataset, first concatenate all FASTQ files into one combined file.

```{bash, echo=TRUE, eval=FALSE}

cat /home/data/projecticum/SW/raw_data/*.fastq.gz > ~/Metagen_SW/raw_data/merged.fastq.gz

```


Then use the FASTQ_NanoPlotter.sh script to create a complete summary report.

cmd usage:  
bash FASTQ_NanoPlotter.sh  
-I ~/Metagen_SW/raw_data  
-O ~/Metagen_SW/analyse  


```{bash, echo=TRUE, eval=FALSE}

#!/bin/bash

# step 1: script description and usage:

print_usage () {
  printf "\nDescription of FASTQ_NanoPlotter.sh: 
  
  This script is used to create NanoPlots of FASTQ files. 
  These plots serve as quality control.
  Designed for long read data only!
  
  Usage: 
  -I input directory with fastq.gz files
  -O output directory (created through script)
  -h for help

  Example cmd line:
	bash FASTQ_NanoPlotter.sh -I path/to/FASTQ/data -O new/ouput/directory\n\n"
}


## step 2: flag definition:

while getopts I:O:h flag; do
  case "${flag}" in
    I) indir="${OPTARG}"  ;;
    O) outdir="${OPTARG}" ;;
    h) print_usage
       exit 1             ;;
    *) echo -e "\nPlease provide valid options (-I and -O are required)."
       echo -e "Use cmd \"bash FASTQ_NanoPlotter.sh -h\" for instructions.\n"
       exit 1             ;;
  esac
done


## step 3: check whether directory -O exists, create if necessary:

if [ ! -d "$outdir" ]; then
  echo -e "\nCreating output directory: $outdir\n"
  mkdir -p "$outdir"
fi


## step 4: NanoPlotting:

for FASTQ in "$indir"/*.fastq.gz; do
  file_name=$(basename "${FASTQ%.fastq.gz}")
  echo "Processing file: $FASTQ"
  NanoPlot --fastq_rich $FASTQ -o "$outdir/$file_name"
  
  #   xdg-open "$outdir/$file_name/NanoPlot-report.html" 
  #-- dit zou beter (algemener) zijn dan volgende line, maar werkt niet. 
  
  xdg-open https://daur.rstudio.hu.nl/s/c310e7760b90faf49cb24/files/Metagen_SW/analyse/merged_test_10/NanoPlot-report.html 
  #-- dit werkt wel.

## step 5: folder cleanup:

echo -e "\nRemoving unnecessary files ..."
find "$outdir" -type f ! -name "NanoPlot-report.html" -exec rm {} +
echo -e "\nNanoPlot created and folder cleaned up."
done

echo -e "\nOpening NanoPlot summary in browser.\n"

```

With this script, a NanoPlot summary document is created as an html file and opened automatically in the browser.

The NanoPlot function has calculated many aspects of the raw FASTQ data. Since the script specified the input as "fastq_rich", the report even generates plots concerning metadata such as the activity of each nanopore channel. The most important information in this document however is in the summary table:

- Mean read length should show that the input data is indeed produced from long read sequencing, since Nanopore is a long read NGS technique (as opposed to 100-150 bp illumina short read sequencing). This is important for downstream analysis.
- Mean read quality takes the average basecall Phred quality score over each read, and then gives the average score of all reads.
- \>Qx shows the proportion of reads with Phred quality score > x. In the SW_Metagen project case, >Q7 shows 100% of all reads, and >Q10 shows <100%. This suggests a preselection of raw data with a minimum Phred quality score cutoff somewhere between 7 and 10.

```{bash, echo=TRUE, eval=FALSE}

#-- HIER KOMT EEN SCRIPT. SCRIPT MAKEN VOOR KRAKEN2.
#-- command in de trend van: kraken2 --db /home/daur2/metagenomics/minikraken2_v2_8GB_201904_UPDATE/ --threads 2 --gzip-compressed --output ~/Metagen_SW/analyse/Kraken2_test_10/test_10.kraken --report ~/Metagen_SW/analyse/Kraken2_test_10/test_10.report --use-names ~/Metagen_SW/raw_data/merged_test_10.fastq.gz

```


